{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VO24y4Jju21u"
   },
   "source": [
    "# Splice site prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhcU9Uucu21v"
   },
   "source": [
    "Gene splicing is a post-transcriptional modification in which a single gene can code for multiple proteins. Gene Splicing is done in eukaryotes, prior to mRNA translation, by the differential inclusion or exclusion of regions of pre-mRNA. Gene splicing is an important source of protein diversity.\n",
    "\n",
    "The vast majority of splice sites are characterized by the presence of specific dimers on the intronic side of the splice site: \"GT\" for donor and \"AG\" for acceptor sites. In this project you will fit a classification model for acceptor splice site prediction in DNA sequences.\n",
    "\n",
    "This model will consider each AG in the DNA as a candidate acceptor site, extract a local context surrounding the candidate acceptor site, represent the candidate site as a feature vector and the predict the class ('acceptor site' or 'not acceptor site') by applying the model in the constructed feature vector.\n",
    "\n",
    "This what the training data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrdBiQtAu21v"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_data/master/practicum/Classification/acceptor_sites_dataset_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "_lJt4Vopu212",
    "outputId": "5be0c1b0-96cc-485c-b776-f05b91617bfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TTTGAATTGTAGGTGTCCTGCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TATTTTTTAAAGAACTGGAAGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TTTCTTTTTCAGATGAAGAATG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TATTAATTTCAGTTTGGTTGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>TAAAAATTTAAGTTCGTCCCGA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                sequence\n",
       "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
       "1      1  TATTTTTTAAAGAACTGGAAGA\n",
       "2      1  TTTCTTTTTCAGATGAAGAATG\n",
       "3      1  TATTAATTTCAGTTTGGTTGTT\n",
       "4      1  TAAAAATTTAAGTTCGTCCCGA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXgIExxtu216"
   },
   "source": [
    "There are just two columns. \n",
    "\n",
    "The column \"sequence\" contains the local context DNA sequence. We can see that nucleotide positions 11 and 12 in the sequence are always \"A\" and \"G\". These are the candidate acceptor sites with a local context that consists of 10 nucleotides upstream en 10 nucleotides downstream the AG. \n",
    "\n",
    "The column \"label\" contains the class of the candidate acceptor site: 1 for \"acceptor site\" and -1 for \"not acceptor site\". \n",
    "\n",
    "*How many sequences does the dataset contain for each class?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "PYhNkKz3u217",
    "outputId": "22209f38-cbcb-47f7-df40-7b83cffc09c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 145 acceptor sites and 1503 non acceptor sites.\n"
     ]
    }
   ],
   "source": [
    "###Start code here\n",
    "\n",
    "acceptor = (data_train['label']==1).value_counts()[1]\n",
    "not_acceptor = (data_train['label']==1).value_counts()[0]\n",
    "print(\"The dataset contains \"+ str(acceptor) + \" acceptor sites and \" + str(not_acceptor) + \" non acceptor sites.\")\n",
    "\n",
    "###End code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_data/master/practicum/Classification/acceptor_sites_dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TATTTTTTTCAGCCAGCAGCAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAACGTTTTCAGACGAGATAGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TGAAGTTTTCAGACAAGATGAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>GCTTTACATTAGGTCCAATGGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>AAAAATTTACAGTCGGAATGCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>-1</td>\n",
       "      <td>TTTGAAGTTTAGCTTCCTTCTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>-1</td>\n",
       "      <td>CTGCTAATATAGTGACAGCAAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>-1</td>\n",
       "      <td>TTCCAAATATAGGAAAATCGAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-1</td>\n",
       "      <td>AAAATGTCGCAGAACAACAAGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>-1</td>\n",
       "      <td>AGAAGTATGGAGGTGGAATGTT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                sequence\n",
       "0        1  TATTTTTTTCAGCCAGCAGCAG\n",
       "1        1  AAACGTTTTCAGACGAGATAGT\n",
       "2        1  TGAAGTTTTCAGACAAGATGAT\n",
       "3        1  GCTTTACATTAGGTCCAATGGG\n",
       "4        1  AAAAATTTACAGTCGGAATGCA\n",
       "..     ...                     ...\n",
       "547     -1  TTTGAAGTTTAGCTTCCTTCTC\n",
       "548     -1  CTGCTAATATAGTGACAGCAAT\n",
       "549     -1  TTCCAAATATAGGAAAATCGAA\n",
       "550     -1  AAAATGTCGCAGAACAACAAGA\n",
       "551     -1  AGAAGTATGGAGGTGGAATGTT\n",
       "\n",
       "[552 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute features from the `column` we first concatenate the training and testing data into one DataFrame. In this manner the training and testing data are processed in exactly the same way. We can later reconstruct the training and testing DataFrames.\n",
    "\n",
    "*Use the Pandas function `concat()` to concatenate the training and testing data into a DataFrame called `data`. The training dat should be the first rows, with the testing data beneath those rows:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TTTGAATTGTAGGTGTCCTGCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TATTTTTTAAAGAACTGGAAGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TTTCTTTTTCAGATGAAGAATG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>TATTAATTTCAGTTTGGTTGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>TAAAAATTTAAGTTCGTCCCGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>-1</td>\n",
       "      <td>TTTGAAGTTTAGCTTCCTTCTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>-1</td>\n",
       "      <td>CTGCTAATATAGTGACAGCAAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>-1</td>\n",
       "      <td>TTCCAAATATAGGAAAATCGAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>-1</td>\n",
       "      <td>AAAATGTCGCAGAACAACAAGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>-1</td>\n",
       "      <td>AGAAGTATGGAGGTGGAATGTT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                sequence\n",
       "0         1  TTTGAATTGTAGGTGTCCTGCT\n",
       "1         1  TATTTTTTAAAGAACTGGAAGA\n",
       "2         1  TTTCTTTTTCAGATGAAGAATG\n",
       "3         1  TATTAATTTCAGTTTGGTTGTT\n",
       "4         1  TAAAAATTTAAGTTCGTCCCGA\n",
       "...     ...                     ...\n",
       "2195     -1  TTTGAAGTTTAGCTTCCTTCTC\n",
       "2196     -1  CTGCTAATATAGTGACAGCAAT\n",
       "2197     -1  TTCCAAATATAGGAAAATCGAA\n",
       "2198     -1  AAAATGTCGCAGAACAACAAGA\n",
       "2199     -1  AGAAGTATGGAGGTGGAATGTT\n",
       "\n",
       "[2200 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Start code here\n",
    "data = pd.concat([data_train, data_test], ignore_index=True)\n",
    "###End code here\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pop the `label` column from the `data` DataFrame and assigned it to variable `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2195   -1\n",
       "2196   -1\n",
       "2197   -1\n",
       "2198   -1\n",
       "2199   -1\n",
       "Name: label, Length: 2200, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Start code here\n",
    "y = data['label']\n",
    "###End code here\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teweqTUhu21_"
   },
   "source": [
    "We need to represent the local context DNA sequence as a feature vector suitable for model fitting. This process is known as **feature engineering**. \n",
    "\n",
    "The \"AG\" dinucleotide in the middle of each local context sequence is the same for both classes, i.e. it does not provide any discriminative information. So, there is not rational behind computing features from this part of the local context sequence.\n",
    "\n",
    "*Use the Pandas DataFrame `.apply()` method to remove the middle \"AG\" dinucleotides in the DNA sequences (don't create a new column):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                sequence\n",
      "0      1  TTTGAATTGTAGGTGTCCTGCT\n",
      "1      1  TATTTTTTAAAGAACTGGAAGA\n",
      "2      1  TTTCTTTTTCAGATGAAGAATG\n",
      "3      1  TATTAATTTCAGTTTGGTTGTT\n",
      "4      1  TAAAAATTTAAGTTCGTCCCGA\n",
      "   label              sequence\n",
      "0      1  TTTGAATTGTGTGTCCTGCT\n",
      "1      1  TATTTTTTAAAACTGGAAGA\n",
      "2      1  TTTCTTTTTCATGAAGAATG\n",
      "3      1  TATTAATTTCTTTGGTTGTT\n",
      "4      1  TAAAAATTTATTCGTCCCGA\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "\n",
    "###Start code here\n",
    "\n",
    "data[\"sequence\"] = data[\"sequence\"].str.slice(stop=10) + data[\"sequence\"].str.slice(start=12)\n",
    "\n",
    "###End code here\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZkQumNiu22E"
   },
   "source": [
    "First, we create a feature for each of the nucleotide positions in the local context DNA sequence.\n",
    "\n",
    "The [pandas.Series.str.split](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) function splits a string in a column (pandas.Series) from the beginning, at the specified delimiter string.\n",
    "\n",
    "*Use this function to split the `sequence` column into one column for each nucleotide positon. Put the resulting columns in a DataFrame called `data_features`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20\n",
       "0     T  T  T  G  A  A  T  T  G  T  G  T  G  T  C  C  T  G  C  T\n",
       "1     T  A  T  T  T  T  T  T  A  A  A  A  C  T  G  G  A  A  G  A\n",
       "2     T  T  T  C  T  T  T  T  T  C  A  T  G  A  A  G  A  A  T  G\n",
       "3     T  A  T  T  A  A  T  T  T  C  T  T  T  G  G  T  T  G  T  T\n",
       "4     T  A  A  A  A  A  T  T  T  A  T  T  C  G  T  C  C  C  G  A\n",
       "...  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n",
       "2195  T  T  T  G  A  A  G  T  T  T  C  T  T  C  C  T  T  C  T  C\n",
       "2196  C  T  G  C  T  A  A  T  A  T  T  G  A  C  A  G  C  A  A  T\n",
       "2197  T  T  C  C  A  A  A  T  A  T  G  A  A  A  A  T  C  G  A  A\n",
       "2198  A  A  A  A  T  G  T  C  G  C  A  A  C  A  A  C  A  A  G  A\n",
       "2199  A  G  A  A  G  T  A  T  G  G  G  T  G  G  A  A  T  G  T  T\n",
       "\n",
       "[2200 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Start code here\n",
    "data_features = data[\"sequence\"].str.split(\"\", expand=True).iloc[:,1:21]\n",
    "###End code here\n",
    "\n",
    "data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Pandas DataFrame, the `.columns` attirbute contains a list with the column names.\n",
    "\n",
    "*Rename the columns to the relative position of the nucleotide position in the local context (from -10 to 10):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-10</th>\n",
       "      <th>-9</th>\n",
       "      <th>-8</th>\n",
       "      <th>-7</th>\n",
       "      <th>-6</th>\n",
       "      <th>-5</th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -10 -9  -8  -7  -6  -5  -4  -3  -2  -1   1   2   3   4   5   6   7   8   \\\n",
       "0      T   T   T   G   A   A   T   T   G   T   G   T   G   T   C   C   T   G   \n",
       "1      T   A   T   T   T   T   T   T   A   A   A   A   C   T   G   G   A   A   \n",
       "2      T   T   T   C   T   T   T   T   T   C   A   T   G   A   A   G   A   A   \n",
       "3      T   A   T   T   A   A   T   T   T   C   T   T   T   G   G   T   T   G   \n",
       "4      T   A   A   A   A   A   T   T   T   A   T   T   C   G   T   C   C   C   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "2195   T   T   T   G   A   A   G   T   T   T   C   T   T   C   C   T   T   C   \n",
       "2196   C   T   G   C   T   A   A   T   A   T   T   G   A   C   A   G   C   A   \n",
       "2197   T   T   C   C   A   A   A   T   A   T   G   A   A   A   A   T   C   G   \n",
       "2198   A   A   A   A   T   G   T   C   G   C   A   A   C   A   A   C   A   A   \n",
       "2199   A   G   A   A   G   T   A   T   G   G   G   T   G   G   A   A   T   G   \n",
       "\n",
       "      9   10  \n",
       "0      C   T  \n",
       "1      G   A  \n",
       "2      T   G  \n",
       "3      T   T  \n",
       "4      G   A  \n",
       "...   ..  ..  \n",
       "2195   T   C  \n",
       "2196   A   T  \n",
       "2197   A   A  \n",
       "2198   G   A  \n",
       "2199   T   T  \n",
       "\n",
       "[2200 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Start code here\n",
    "data_features.columns = list(range(-10,0,1)) + list(range(1,11,1))\n",
    "###End code here\n",
    "\n",
    "data_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MJXJBj0u22I"
   },
   "source": [
    "Next we apply `sklearn.preprocessing.LabelEncoder` to repace each nucleotide by a number.\n",
    "\n",
    "*Create a Pandas DataFrame `data_features_int_encoding` by applying the `LabelEncoder` on each feature in `data_features`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "nFRdEtCeu22J",
    "outputId": "aa2c17a9-c4bb-46ab-f781-9b9d276e8e59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-10</th>\n",
       "      <th>-9</th>\n",
       "      <th>-8</th>\n",
       "      <th>-7</th>\n",
       "      <th>-6</th>\n",
       "      <th>-5</th>\n",
       "      <th>-4</th>\n",
       "      <th>-3</th>\n",
       "      <th>-2</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   -10  -9   -8   -7   -6   -5   -4   -3   -2   -1    1    2    3    4    5   \\\n",
       "0    3    3    3    2    0    0    3    3    2    3    2    3    2    3    1   \n",
       "1    3    0    3    3    3    3    3    3    0    0    0    0    1    3    2   \n",
       "2    3    3    3    1    3    3    3    3    3    1    0    3    2    0    0   \n",
       "3    3    0    3    3    0    0    3    3    3    1    3    3    3    2    2   \n",
       "4    3    0    0    0    0    0    3    3    3    0    3    3    1    2    3   \n",
       "\n",
       "    6    7    8    9    10  \n",
       "0    1    3    2    1    3  \n",
       "1    2    0    0    2    0  \n",
       "2    2    0    0    3    2  \n",
       "3    3    3    2    3    3  \n",
       "4    1    1    1    2    0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "data_features_int_encoding = pd.DataFrame()\n",
    "for col in data_features.columns:\n",
    "    ###Start code here\n",
    "    data_features_int_encoding[col] = labelencoder.fit_transform(data_features[col].values.flatten())\n",
    "    ###End code here\n",
    "    \n",
    "data_features_int_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we recontruct the training and testing data DataFrames based on the number of datapoints in the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_int_encoding_train = data_features_int_encoding.iloc[:len(data_train),:]\n",
    "data_features_int_encoding_test = data_features_int_encoding.iloc[len(data_train):,:]\n",
    "\n",
    "y_train = y.iloc[:len(data_train)]\n",
    "y_test = y.iloc[len(data_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0573K2rRu22W"
   },
   "source": [
    "Now we evaluate the generalization performance of a logistic regression model with hyperparameters $C=0.1$ on the dataset `data_features_int_encoding` using 10-fold cross-validation. \n",
    "\n",
    "*Apply the `cross_val_score()` function to compute an accuracy score for each fold in the CV:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "jc7J8SrIu22X",
    "outputId": "5d9ba961-b669-4a94-a9d7-5243d57cab27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9253658536585366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "###Start code here\n",
    "model = LogisticRegression(C=0.1)\n",
    "scores = cross_val_score(model, data_features_int_encoding_train, y_train, cv=10)\n",
    "###Start code here\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9SWqTScu22u"
   },
   "source": [
    "*Fit a logistic regression model on the train set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "gHuDj5xsu22v",
    "outputId": "d8c46421-8aa9-4abe-9fd3-e1c1c7397ea3"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "LogReg = model.fit(data_features_int_encoding_train, y_train)\n",
    "\n",
    "###End code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_gu0seZu221"
   },
   "source": [
    "*Make predictions for the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzX1UJqlu222"
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "predictions = model.predict(data_features_int_encoding_test)\n",
    "###End code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNIux5gFu227"
   },
   "source": [
    "Scikit-learn offers many metrics to evaluate model predictions. These functions are contained in the `metrics` module of `sklearn`. \n",
    "\n",
    "*Can you find how to compute the accuracy of these predictions (use the `metrics`module)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "TTFGB05gu228",
    "outputId": "ab15f4d5-af1a-4f1d-c3ba-c377dbf3abf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221014492753623\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "###Start code here\n",
    "score_acc = metrics.accuracy_score(y_test, predictions)\n",
    "###End code here\n",
    "\n",
    "print(score_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPu8YDA2u23D"
   },
   "source": [
    "An accuracy above 90% seems like a good score. But is it? Let's consider a model that predicts class \"-1\" for all test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kV1yMLOu23E"
   },
   "outputs": [],
   "source": [
    "predictions_zero = [-1]*len(data_test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efNP_I-Ju23I"
   },
   "source": [
    "*What is the accuracy of these predictions?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "fmdBsSaou23K",
    "outputId": "a4efb18f-1f8a-4cb3-e49b-16ae5938a95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9003623188405797\n"
     ]
    }
   ],
   "source": [
    "###Start code here\n",
    "score_acc = metrics.accuracy_score(y_test, predictions_zero)\n",
    "###End code here\n",
    "\n",
    "print(score_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lZ3nJUPu23P"
   },
   "source": [
    "So this should be a good score as well, even though we did not learn anything.\n",
    "\n",
    "For classification tasks where the classes are highly imbalanced, accuracy is not a good metric to evaluate the generalization performance. In fact, if there are 0.1% \"AG\" dinucleotides in a genome that are true acceptor sites then a model that predicts class \"-1\" for each \"AG\" would have an accuracy of 99.9%.\n",
    "\n",
    "We have seen how a ROC curve plots the true positives rate against the false positives rate. Both these metrics focus on the positive class, in our case the true acceptor sites. These metrics are much more suitable to evalute the performance of models on tasks with highly imbalanced classes. To transform a ROC curve into one metric we can use the area under the curve (AUC). \n",
    "\n",
    "*What is the AUC score of the predictions computed by the linear regression model we fitted?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "nTjM_o7Iu23Q",
    "outputId": "f9c9fda5-fa07-4452-cf35-8e36ad114b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6737698920797514\n"
     ]
    }
   ],
   "source": [
    "###Start code here\n",
    "score_auc = metrics.roc_auc_score(y_test, predictions)\n",
    "###End code here\n",
    "\n",
    "print(score_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbuR3_0Uu23V"
   },
   "source": [
    "To compute the AUC, we actually need the predictions to be scores (a continuous value) rather than class labels (discrete values).\n",
    "\n",
    "For logistic regression these scores are the class probabilities predicted by the model (a value between 0 and 1). \n",
    "\n",
    "We can obtain these scores with the `predict_proba()` function of the `LogisticRegression` module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "xMT2X0i7u23W",
    "outputId": "069d78eb-be22-401c-cf3d-c98ad4fc5a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33015439 0.66984561]\n",
      " [0.44977258 0.55022742]\n",
      " [0.34876393 0.65123607]\n",
      " ...\n",
      " [0.99674001 0.00325999]\n",
      " [0.9820754  0.0179246 ]\n",
      " [0.982688   0.017312  ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_proba(data_features_int_encoding_test)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecMykZJcu23h"
   },
   "source": [
    "The first and second column contain the predicted probabilities for class '-1' and '1' respectively. To compute the AUC we need to use the positive class probabilities. \n",
    "\n",
    "*What is the AUC now?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "k7Zj60JBu23i",
    "outputId": "d32a2e3d-6baa-43ee-969f-afa70c6f08e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8841046277665996\n"
     ]
    }
   ],
   "source": [
    "###Start code here\n",
    "score_auc = metrics.roc_auc_score(y_test, predictions[:,1])\n",
    "###End code here\n",
    "\n",
    "print(score_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EudhUPu-u23o"
   },
   "source": [
    "Is this good generalization performance?\n",
    "\n",
    "Transforming categorical features into ordered integers is maybe not a good idea as the nucleotides don't have any ordering (the columns are not ordinal features). \n",
    "\n",
    "It is better to transform a categorical feature into one binary feature for each category (known as *one-hot* encoding). \n",
    "\n",
    "*Use the Pandas function `get_dummies()` to compute one-hot encoded features (put them in a DataFrame called `data_features_onehot_encoding`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-10_A</th>\n",
       "      <th>-10_C</th>\n",
       "      <th>-10_G</th>\n",
       "      <th>-10_T</th>\n",
       "      <th>-9_A</th>\n",
       "      <th>-9_C</th>\n",
       "      <th>-9_G</th>\n",
       "      <th>-9_T</th>\n",
       "      <th>-8_A</th>\n",
       "      <th>-8_C</th>\n",
       "      <th>...</th>\n",
       "      <th>8_G</th>\n",
       "      <th>8_T</th>\n",
       "      <th>9_A</th>\n",
       "      <th>9_C</th>\n",
       "      <th>9_G</th>\n",
       "      <th>9_T</th>\n",
       "      <th>10_A</th>\n",
       "      <th>10_C</th>\n",
       "      <th>10_G</th>\n",
       "      <th>10_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -10_A  -10_C  -10_G  -10_T  -9_A  -9_C  -9_G  -9_T  -8_A  -8_C  ...  \\\n",
       "0         0      0      0      1     0     0     0     1     0     0  ...   \n",
       "1         0      0      0      1     1     0     0     0     0     0  ...   \n",
       "2         0      0      0      1     0     0     0     1     0     0  ...   \n",
       "3         0      0      0      1     1     0     0     0     0     0  ...   \n",
       "4         0      0      0      1     1     0     0     0     1     0  ...   \n",
       "...     ...    ...    ...    ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "2195      0      0      0      1     0     0     0     1     0     0  ...   \n",
       "2196      0      1      0      0     0     0     0     1     0     0  ...   \n",
       "2197      0      0      0      1     0     0     0     1     0     1  ...   \n",
       "2198      1      0      0      0     1     0     0     0     1     0  ...   \n",
       "2199      1      0      0      0     0     0     1     0     1     0  ...   \n",
       "\n",
       "      8_G  8_T  9_A  9_C  9_G  9_T  10_A  10_C  10_G  10_T  \n",
       "0       1    0    0    1    0    0     0     0     0     1  \n",
       "1       0    0    0    0    1    0     1     0     0     0  \n",
       "2       0    0    0    0    0    1     0     0     1     0  \n",
       "3       1    0    0    0    0    1     0     0     0     1  \n",
       "4       0    0    0    0    1    0     1     0     0     0  \n",
       "...   ...  ...  ...  ...  ...  ...   ...   ...   ...   ...  \n",
       "2195    0    0    0    0    0    1     0     1     0     0  \n",
       "2196    0    0    1    0    0    0     0     0     0     1  \n",
       "2197    1    0    1    0    0    0     1     0     0     0  \n",
       "2198    0    0    0    0    1    0     1     0     0     0  \n",
       "2199    1    0    0    0    0    1     0     0     0     1  \n",
       "\n",
       "[2200 rows x 80 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Start code here\n",
    "data_features_onehot_encoding = pd.get_dummies(data_features)\n",
    "###End code here\n",
    "\n",
    "data_features_onehot_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfAOG8SBu24E"
   },
   "source": [
    "Evaluate the generalization performance of a logisitc regression model with hyperparameters $C=1$ on the training data in `data_features_onehot_encoding` using 10-fold cross-validation. \n",
    "\n",
    "The `cross_val_score()` has a function parameter called `scoring` that allows you to set different scoring metrics.\n",
    "\n",
    "*Use the `cross_val_score()` function to compute the mean AUC of the CV-scores.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "bq2cZVNSu24F",
    "outputId": "159ebfd3-fb04-40af-a6b2-8137aab19f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9847463891516872\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "\n",
    "###Start code here\n",
    "data_features_onehot_encoding_train = data_features_onehot_encoding.iloc[:len(data_train),:]\n",
    "y_onehot_encoding_train = y.iloc[:len(data_train)]\n",
    "\n",
    "score_auc = np.mean(cross_val_score(model, data_features_onehot_encoding_train, y_onehot_encoding_train, cv=10, scoring='roc_auc'))\n",
    "###End code here\n",
    "\n",
    "print(score_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vqh-I3zuu24L"
   },
   "source": [
    "*What is the AUC on `data_test`?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "GeCkxuubu24M",
    "outputId": "502dc7a6-1997-4961-8a70-bc1a02b4b6bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892043537414966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Start code here\n",
    "data_features_onehot_encoding_test = data_features_onehot_encoding.iloc[:len(data_test),:]\n",
    "y_onehot_encoding_test = y.iloc[len(data_train):]\n",
    "\n",
    "score_auc = np.mean(cross_val_score(model, data_features_onehot_encoding_test, y_onehot_encoding_test, cv=10, scoring='roc_auc'))\n",
    "\n",
    "###Start code here\n",
    "\n",
    "score_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2w-jdU-gu24Q"
   },
   "source": [
    "Is this close to what your CV is telling you?\n",
    "\n",
    "We have used hyperparameter $C=1$ for the logistic regression model. \n",
    "\n",
    "*Is there a better value for this regularization parameter (use `GridSearchCV`)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B63LA0zwu24S",
    "outputId": "1e4c5b6c-d833-4c9e-f6bb-2cc1e8c817e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
      "LogisticRegression(C=1)\n",
      "0.9666335083356359\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_space = [0.001,0.01,0.1,1,10,100]\n",
    "params = dict(C=search_space)\n",
    "print(params)\n",
    "\n",
    "###Start code here\n",
    "\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(model, params)\n",
    "grid_search.fit(data_features_onehot_encoding_train,y_onehot_encoding_train)\n",
    "\n",
    "###End code here\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjoFP1_bu24W"
   },
   "source": [
    "*What is the 10-CV AUC performance with this value for $C$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "hWxVj0hRu24X",
    "outputId": "6330ac78-44b6-43c2-da1f-8798b3b1a1f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847463891516872"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "###Start code here\n",
    "\n",
    "score_auc = np.mean(cross_val_score(model, data_features_onehot_encoding_train, y_onehot_encoding_train, cv=10, scoring='roc_auc'))\n",
    "\n",
    "###Start code here\n",
    "\n",
    "score_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ytpwmh2wu24c"
   },
   "source": [
    "*What is the AUC performance on the test set for this value of $C$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "k5906bHvu24d",
    "outputId": "917b912d-3596-4670-940d-8057286470f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892043537414966"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=1)\n",
    "###Start code here\n",
    "\n",
    "score_auc = np.mean(cross_val_score(model, data_features_onehot_encoding_test, y_onehot_encoding_test, cv=10, scoring='roc_auc'))\n",
    "\n",
    "###End code here\n",
    "\n",
    "score_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "wRe1CLnUu24l"
   },
   "source": [
    "Is this closer to the AUC you computed using 10-CV?\n",
    "\n",
    "In scikit-learn a fitted logistic regression model has the fitted modelparameter values stored in `.coef_[0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "8f-NBEUt4AjE",
    "outputId": "403323ff-3fba-48c0-b898-ad01850826bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47913801 -0.21734157 -0.84815424  0.58622429  0.32255299 -0.38610416\n",
      " -0.73300594  0.79642359  0.43271421 -0.17206379 -0.82147414  0.5606902\n",
      "  0.11079628 -0.43093542 -0.31934691  0.63935255  0.86601068 -1.25349266\n",
      " -0.63738888  1.02473735 -0.11861092  0.06926326 -0.70450688  0.75372103\n",
      " -0.4718082  -0.6467675  -0.91722143  2.03566361 -1.27747723 -0.55827664\n",
      " -0.8625858   2.69820616 -0.11954326 -0.47204416 -0.84161892  1.43307283\n",
      " -0.64123723  2.05912016 -1.72034224  0.3023258   0.44369177 -0.72487884\n",
      "  1.11200797 -0.83095441 -0.07735498 -0.10416085  0.25928459 -0.07790228\n",
      "  0.03041843  0.1905419   0.2637964  -0.48489024 -0.32530546  0.44472124\n",
      "  0.26691915 -0.38646844 -0.66201988  0.57906414  0.50459143 -0.42176919\n",
      " -0.23317418  0.42568974  0.46338059 -0.65602966 -0.62006953  0.33864329\n",
      "  0.587697   -0.30640428 -0.14253564  0.225374    0.3280646  -0.41103648\n",
      " -0.07642458  0.51808758 -0.30303357 -0.13876294 -0.57864226  0.116347\n",
      "  0.69097627 -0.22881452]\n"
     ]
    }
   ],
   "source": [
    "print(model.fit(data_features_onehot_encoding_train,y_onehot_encoding_train).coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdPAICuc4NWT"
   },
   "source": [
    "For logistic regression this is one modelparameter for each feature (plus the interecept, which is not in `.coef_[0]`). \n",
    "\n",
    "Recall that for logistic regression a prediction is made by multiplying each fitted modelparameter with the corresponding feature, summing them and then squeezing this sum between 0 and 1 with the logistic function. \n",
    "\n",
    "Since all features have values 0 or 1, the modelparameter values indicate the contribution (importance) of a feature during prediction.\n",
    "\n",
    "First we put the feature names and modelparameter values in a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "1Mnte18-u242",
    "outputId": "74bff443-ad92-46cb-e5a2-cfee028d100f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10_A</td>\n",
       "      <td>0.479138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10_C</td>\n",
       "      <td>-0.217342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10_G</td>\n",
       "      <td>-0.848154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10_T</td>\n",
       "      <td>0.586224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9_A</td>\n",
       "      <td>0.322553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>9_T</td>\n",
       "      <td>-0.138763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10_A</td>\n",
       "      <td>-0.578642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10_C</td>\n",
       "      <td>0.116347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10_G</td>\n",
       "      <td>0.690976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10_T</td>\n",
       "      <td>-0.228815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_name  importance\n",
       "0         -10_A    0.479138\n",
       "1         -10_C   -0.217342\n",
       "2         -10_G   -0.848154\n",
       "3         -10_T    0.586224\n",
       "4          -9_A    0.322553\n",
       "..          ...         ...\n",
       "75          9_T   -0.138763\n",
       "76         10_A   -0.578642\n",
       "77         10_C    0.116347\n",
       "78         10_G    0.690976\n",
       "79         10_T   -0.228815\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_importances = []\n",
    "for feature_name, modelparameter in zip(data_features_onehot_encoding.columns,model.coef_[0]):\n",
    "    F_importances.append([feature_name,modelparameter])\n",
    "F_importances = pd.DataFrame(F_importances,columns=[\"feature_name\",\"importance\"])\n",
    "F_importances   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SwWB_xQ8w8g"
   },
   "source": [
    "*Use the Seaborn `.barplot()` method to create a plot like this:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0N9sbu79xoi"
   },
   "source": [
    "*Create a plot that looks like this:*\n",
    "\n",
    "![plot](https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_data/master/practicum/Classification/AG_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "id": "ntsnD5Kwu25B",
    "outputId": "562c9b9d-110f-4923-e0ac-b259a3f7dedc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI4AAAJNCAYAAABXxz65AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAs7ElEQVR4nO3dfbikZX0n+O8vNAQUMIAkwWALuoMRlpdAg3E6QzO+6yQqUSPGtZHEGDPYalaNbrLbtsx17aXiJKPoxDXiCy7CKAoxG01CfOnW1hC6SWuDqHEcwR5RWzQKIoJw7x+n6DTNDVRD1XnOqfP5XFdfnKp6qp7vTXVX1fnW/dxPtdYCAAAAALv6maEDAAAAALAwKY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAICuZUMH2B0PfvCD22GHHTZ0DAAAAICZsXnz5u+21g7u3baoiqPDDjssmzZtGjoGAAAAwMyoqmvu7jaHqgEAAADQpTgCAAAAoEtxBAAAAEDXolrjCAAAAGASbr311mzbti0333zz0FHmzd57751DDz00e+6559j3URwBAAAAS862bduy33775bDDDktVDR1n6lpruf7667Nt27YcfvjhY9/PoWoAAADAknPzzTfnoIMOWhKlUZJUVQ466KDdnmGlOAIAAACWpKVSGt3hvoxXcQQAAACQuWLlFa94xY7Lb3rTm7Ju3br79FgveMELctFFF92n+77nPe/JN7/5zR2XX/jCF+aLX/xid7uXvOQl92kf41IcAQAAACT52Z/92Xz4wx/Od7/73UFz7FocvfOd78yRRx45SBbFEQAAAECSZcuW5UUvelH+7M/+7C637TqDaN99993x8xvf+MYcffTROfbYY/Oa17zmLvfdvHlzVq1alRNOOCFPetKTct111yVJtmzZkl/91V/NMccck1NPPTXf//73c9FFF2XTpk153vOel+OOOy4//vGPc8opp2TTpk1Jkne/+9054ogjsmrVqmzcuHHHPrZv355nPvOZOfHEE3PiiSfe6bb7Q3EEAAAAMHLmmWfm/PPPzw9+8IOxtv/Yxz6WSy65JJdddlk+//nP54/+6I/udPutt96aNWvW5KKLLsrmzZvzO7/zO/mTP/mTJMnq1avzhje8IV/4whdy9NFH53Wve12e9axnZcWKFTn//POzZcuW7LPPPjse67rrrstrX/vabNy4MZdeeumdDl972ctelj/8wz/M5Zdfng996EN54QtfOIH/G8myiTwKAAAAwAzYf//9s3r16rzlLW+5U2lzd/7+7/8+Z5xxRh7wgAckSQ488MA73f7lL385V155ZZ7whCckSW677bYccsgh+cEPfpB/+Zd/yapVq5Ikp59+ep797Gff474uu+yynHLKKTn44IOTJM95znPyla98ZUeOnYukH/7wh7nhhhuy3377jTnyPsURAAAAwE5e/vKX5/jjj88ZZ5yx47ply5bl9ttvT5K01nLLLbfs+PmezlbWWstRRx2Vz33uc3e6ftwZTbu6u33dfvvt+dznPjdW2bU7HKoGAAAAsJMDDzwwv/Vbv5Vzzz13x3WHHXZYNm/enCT5y7/8y9x6661Jkic+8Yl517velZtuuilJ8r3vfe9Oj/XIRz4y27dv31Ec3XrrrbnqqqvyoAc9KAcccEA+/elPJ0ne97737Zh9tN9+++WGG264S65HP/rR+dSnPpXrr78+t956az74wQ/uuO2JT3xi3vrWt+64vGXLlvv7vyGJ4ggAAADgLl7xilfc6exqv/d7v5f169fnpJNOymWXXZYHPvCBSZInP/nJedrTnpYVK1bkuOOOy5ve9KY7Pc5ee+2Viy66KK9+9atz7LHH5rjjjstnP/vZJMl73/vevOpVr8oxxxyTLVu2ZO3atUnmFuJ+8YtfvGNx7DsccsghWbduXR7zmMfk8Y9/fI4//vgdt73lLW/Jpk2bcswxx+TII4/M29/+9on8f6jW2kQeaD6sWLGi3bGKOAAAAMB9dfXVV+dRj3rU0DHmXW/cVbW5tbait70ZRwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAADAAnbxxRenqvKlL31p3ve9bN73CABLxPqTV4297aoN66eYBACASTjhVedN9PE2n716rO0uuOCC/Nqv/VouvPDCrFu3bqIZ7o0ZRwAAAAAL1I033piNGzfm3HPPzYUXXjjv+1ccAQAAACxQl1xySZ785CfniCOOyIEHHpgrrrhiXvevOAIAAABYoC644IKcdtppSZLTTjstF1xwwbzu3xpHAAAAAAvQ9ddfn0984hO58sorU1W57bbbUlV54xvfmKqalwxmHAEAAAAsQBdddFFWr16da665Jl//+tfzjW98I4cffng+85nPzFsGxREAAADAAnTBBRfk1FNPvdN1z3zmM/P+979/3jI4VA0AAABgDJvPXj2v+/vUpz51l+te+tKXzmsGM44AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAgAXsW9/6Vk477bQ84hGPyJFHHpmnPvWp+cpXvjIv+142L3sBAAAAWOSuPevoiT7e8rVb73Wb1lpOPfXUnH766bnwwguTJFu2bMm3v/3tHHHEERPN06M4AgAAAFigPvnJT2bPPffMi1/84h3XHXfccfO2f4eqAQAAACxQV155ZU444YTB9q84AgAAAKBLcQQAAACwQB111FHZvHnzYPtXHAEAAAAsUI997GPzk5/8JH/xF3+x47rLL78869evn5f9K44AAAAAFqiqysUXX5xLL700j3jEI3LUUUdl3bp1echDHjIv+3dWNQAAAIAxLF+7dZD9PuQhD8kHPvCBQfZtxhEAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAsIB9+9vfzm//9m/n4Q9/eE444YQ85jGPycUXXzwv+142L3sBAAAAWORWnrNyoo+3cc3Ge92mtZZnPOMZOf300/P+978/SXLNNdfkIx/5yESz3B0zjgAAAAAWqE984hPZa6+98uIXv3jHdQ972MOyZs2aedm/4ggAAABggbrqqqty/PHHD7Z/xREAAADAInHmmWfm2GOPzYknnjgv+1McAQAAACxQRx11VK644oodl9/2trfl4x//eLZv3z4v+1ccAQAAACxQj33sY3PzzTfnz//8z3dcd9NNN83b/hVHAAAAAAtUVeWSSy7J+vXrc/jhh+ekk07K6aefnje84Q3zsv9l87IXAAAAgEVu45qNg+z3kEMOyYUXXjjIvs04AgAAAKBLcQQAAABAl+IIAAAAgC7FEQAAAABdiiMAAAAAuhRHAAAAAHQtGzoAAAAAAHd1/fXX53GPe1yS5Fvf+lb22GOPHHzwwUmSf/zHf8xee+019QyKIwAAAIAxrD951UQfb9WG9fd4+0EHHZQtW7YkSdatW5d99903r3zlKyea4d44VA0AAACALsURAAAAAF2KIwAAAAC6FEcAAAAAdCmOAAAAAOhSHAEAAADQtWzoAAAAAACLwaoN6wfb97p16wbZrxlHAAAAAHQpjgAAAADoUhwBAAAA0KU4AgAAAJak1trQEebVfRmv4ggAAABYcvbee+9cf/31S6Y8aq3l+uuvz957771b93NWNQAAAGDJOfTQQ7Nt27Zs37596CjzZu+9986hhx66W/dRHAEAAABLzp577pnDDz986BgLnkPVAAAAAOhSHAEAAADQpTgCAAAAoEtxBAAAAECX4ggAAACALsURAAAAAF2KIwAAAAC6FEcAAAAAdCmOAAAAAOhSHAEAAADQpTgCAAAAoGvZ0AEAAO6ra886euxtl6/dOsUkAACzyYwjAAAAALoURwAAAAB0DXaoWlU9NMl5SX4xye1J3tFae/NQeQCYf+tPXjX2tqs2rJ9iEgAAoGfINY5+muQVrbUrqmq/JJur6tLW2hcHzAQAAADAyGCHqrXWrmutXTH6+YYkVyf5paHyAAAAAHBnC2KNo6o6LMmvJLls4CgAAAAAjAxeHFXVvkk+lOTlrbUfdm5/UVVtqqpN27dvn/+AAAAAAEvUoMVRVe2ZudLo/Nbah3vbtNbe0Vpb0VpbcfDBB89vQAAAAIAlbLDiqKoqyblJrm6t/elQOQAAAADoG3LG0cokz0/y2KraMvrz1AHzAAAAALCTZUPtuLX2mSQ11P4BAAAAuGeDL44NAAAAwMKkOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACga9nQAQCAxWf9yat2a/tVG9ZPKQkAANNkxhEAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0LRs6AAAA99/Kc1aOve3GNRunmAQAmCVmHAEAAADQpTgCAAAAoEtxBAAAAECX4ggAAACALsURAAAAAF2KIwAAAAC6FEcAAAAAdCmOAAAAAOgatDiqqndV1Xeq6sohcwAAAABwV8sG3v97krw1yXkD5wAWqfUnrxp721Ub1k8xCQAAwOwZdMZRa21Dku8NmQEAAACAPmscAQAAANC14IujqnpRVW2qqk3bt28fOg4AAADAkrHgi6PW2jtaaytaaysOPvjgoeMAAAAALBkLvjgCAAAAYBiDFkdVdUGSzyV5ZFVtq6rfHTIPAAAAAP9q2ZA7b609d8j9AwAAAHD3HKoGAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAICuZUMHABavE1513tjbbj579RSTAAAAMA1mHAEAAADQpTgCAAAAoEtxBAAAAECX4ggAAACALsURAAAAAF2KIwAAAAC6FEcAAAAAdC0bOgCLw/qTV4297aoN66eYBAAAAJgvZhwBAAAA0KU4AgAAAKBLcQQAAABAlzWOABYw64sBAABDMuMIAAAAgC7FEQAAAABdYxdHVfWwqnr86Od9qmq/6cUCAAAAYGhjFUdV9XtJLkry/4yuOjTJJVPKBAAAAMACMO6MozOTrEzywyRprf1zkp+fVigAAAAAhjducfST1totd1yoqmVJ2nQiAQAAALAQLBtzu/VV9cdJ9qmqJyT5j0n+anqxAAAAAJamleesHHvbjWs2TjHJ+DOOXpNke5KtSX4/yUeT/J/TCgUAAADA8MadcbRPkne11v4iSapqj9F1N00rGAAAAADDGnfG0cczVxTdYZ8kfz/5OAAAAAAsFOMWR3u31m6848Lo5wdMJxIAAAAAC8G4xdGPqur4Oy5U1QlJfjydSAAAAAAsBOOucfTyJB+sqm+OLh+S5DlTSQRM1PqTV+3W9qs2rJ9SEgAAABabsYqj1trlVfXLSR6ZpJJ8qbV261STAQAAADCocWccJcmJSQ4b3edXqiqttfOmkgoAAACAwY1VHFXV+5I8IsmWJLeNrm5JFEcAAAAAM2rcGUcrkhzZWmvTDAMAAADAwjHuWdWuTPKL0wwCAAAAwMIy7oyjByf5YlX9Y5Kf3HFla+1pU0m1CO3OmauctQoAAGB4K89ZOfa2G9dsnGISWLjGLY7WTTMEAADAQnHtWUePve3ytVunmARgeGMVR601U2QAAAAAlphxz6r2q0nOSfKoJHsl2SPJj1pr+08xG8wbhxoCAADAXY27OPZbkzw3yT8n2SfJC0fXAQAAADCjxl3jKK21r1bVHq2125K8u6o+O8VcAAAAAAxs3OLopqraK8mWqnpjkuuSPHB6sQAAAAAY2riHqj1/tO1LkvwoyUOT/Oa0QgEAAAAwvHFnHD2jtfbmJDcneV2SVNXLkrx5WsEAAACApePas44ee9vla7dOMQk7G7c4Oj13LYle0LkOAABgyVh5zsqxt924ZuMUkwBMxz0WR1X13CS/neThVfWRnW7aL8n10wwGAAAAwLDubcbRZzO3EPaDk/znna6/IckXphUKAAAAgOHdY3HUWrumqrYl+VFrbf08ZdptJ7zqvLG33Xz26ikmAQAAAJgd93pWtdbabUluqqoHzUMeAAAAABaIcRfHvjnJ1qq6NMmP7riytfbSqaQCAABgcBb/BsYtjv569AcAAACAJWKs4qi19t6q2ivJEaOrvtxau3V6sQAAZpO1GZkF15519NjbLl+7dYpJAJi2sYqjqjolyXuTfD1JJXloVZ3eWtswtWQsCT48AwAAwMI17qFq/znJE1trX06SqjoiyQVJTphWMAAAACZvd2aM5YD9pxcEWBTu9axqI3veURolSWvtK0n2nE4kAAAAABaCcWccbaqqc5O8b3T5eUk2TycSAAAAAAvBuMXRHyQ5M8lLM7fG0YYk/3VaoQAAAAAY3rhnVftJVb01yceT3J65s6rdMtVkAAAAAAxq3LOq/Yckb0/y3zM34+jwqvr91trHphkOAAAAgOHszlnV/n1r7atJUlWPSPLXSRRHAAAAADNq3LOqfeeO0mjka0m+M4U8AAAAACwQ4844uqqqPprkA0lakmcnubyqfjNJWmsfnlI+AAAAAAYybnG0d5JvJ1k1urw9yYFJfiNzRZLiCAAAAGDGjHtWtTOmHQQAAADuj2vPOnr37nDA/tMJAjNk3LOqHZ5kTZLDdr5Pa+1p04kFAAAA3Fcrz1m5W9tvXLNxSklY7MY9VO2SJOcm+askt08tDXdxwqvOG3vbzWevnmISAAAAYKkZtzi6ubX2lqkmAQAAAGBBGbc4enNVvTbJ3yX5yR1XttaumEoqAIABrT951b1vNLJqw/opJgEAGNa4xdHRSZ6f5LH510PV2ugyAAAAADNo3OLo1CQPb63dMs0wAAAAACwcPzPmdp9P8nNTzAEAAADAAjPujKNfSPKlqro8d17j6GlTSQUAAEvErJ8ye3fGt9jGBrAUjFscvXaqKQAA4B4oHwBgGGMVR601pwsBAAAAWGLusTiqqhsyd/a0u9yUpLXW9p9KKgAAAAAGd4/FUWttv/kKAgAAANy9a886evyNDzDPg8kY96xqAAAAACwxiiMAAAAAuhRHAAAAAHSNdVY1AABgfNYhAWBWmHEEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACga9nQAWCWnfCq88bedvPZq6eYBAAAgCFde9bR4298wP7TC7KbzDgCAAAAoEtxBAAAAECX4ggAAACALsURAAAAAF0WxwaYgN1Z6G752q1TTAIAADA5ZhwBAAAA0KU4AgAAAKBLcQQAAABA16BrHFXVk5O8OckeSd7ZWnv9kHkAAODunPCq88be9uL9phgEAObRYDOOqmqPJG9L8pQkRyZ5blUdOVQeAAAAAO5syEPVTkry1dba11prtyS5MMnTB8wDAAAAwE6GLI5+Kck3drq8bXQdAAAAAAtAtdaG2XHVs5M8qbX2wtHl5yc5qbW2ZpftXpTkRUmyfPnyE6655pr7td9rzzp67G2fe8D+Y2+7cc3G+xJnonZnbMlsj293xpbM9vgWwtiSxTm+3VnLYvPZq8feduU5K8fedlrj2711Os7ercdeCM/ftMa3UF5bFsL4/NubH7vz2rl87daxt11/8qqxt121Yf3Y207ztWUhjG+hWAjP3+7829sduzO2ZLbHt7t/N2d5fAthbInx7WwhjG933tf/7w/u3vLOC2F8u2MSz11VbW6trejdNuSMo21JHrrT5UOTfHPXjVpr72itrWitrTj44IPnLRwAAADAUjdkcXR5kn9TVYdX1V5JTkvykQHzAAAAALCT3ZuvNUGttZ9W1UuS/G2SPZK8q7V21VB5AAAAALizwYqjJGmtfTTJR4fMAAAAAEDfkIeqAQAAALCAKY4AAAAA6FIcAQAAANA16BpHAADMjs1nrx5722vPOntqOVZtWD+1xwZg9+zOewMLkxlHAAAAAHQpjgAAAADocqgaAADzbvnarUNHAADGYMYRAAAAAF1mHAHcDQv5sVAtlAWIAQCYfWYcAQAAANBlxhEAAAAws1ZtWD90hEVNcQQAAAADsTwCC51D1QAAAADoUhwBAAAA0OVQNRaN5Wu3jr/xOSunFwQAAACWCDOOAAAAAOhSHAEAAADQpTgCAAAAoEtxBAAAAEDXklsc2wLLAAAAAONZcsURAAAAwKxYtWH9VB9fcQQAALDIbT579dARgBlljSMAAAAAuhRHAAAAAHQpjgAAAADoUhwBAAAA0KU4AgAAAKBLcQQAAABAl+IIAAAAgK5lQwcAAACAhW7VhvVDR2AnG9dsHDrCkqE4gkXIiyQAAADzQXEEAABk89mrh44AwAJkjSMAAAAAuhRHAAAAAHQpjgAAAADoUhwBAAAA0KU4AgAAAKBLcQQAAABA17KhAzA5y9du3b07nLNyOkEAAOA+WLVh/dARANiFGUcAAAAAdCmOAAAAAOhyqBoAAAAscQ4V5e4ojgAAAOaBX8yBxUhxBAvEbi9uDgAAAFNmjSMAAAAAuhRHAAAAAHQpjgAAAADossYRwBK0+ezVY2977VlnTzEJ07Zb66eds3J6QQAAWJTMOAIAAACgy4wjAABYRJzSHYD5ZMYRAAAAAF2KIwAAAAC6FEcAAAAAdCmOAAAAAOhSHAEAAADQpTgCAAAAoEtxBAAAAEDXsqEDAMCQlq/dOv7G56ycXhAAAFiAzDgCAAAAoMuMIwAAAID7YPPZq4eOMHVmHAEAAADQpTgCAAAAoEtxBAAAAECX4ggAAACALotjAwAAsGAthcWHYSEz4wgAAACALjOOgAVn45qNQ0cABuSbZQCAhUNxBMA9Wr526+7d4ZyV0wkCAADMO8URAAAA99uqDeuHjgBMgeIIAACYeQ6DBbhvLI4NAAAAQJfiCAAAAIAuxREAAAAAXdY4AphnG9dsHDoCAADAWMw4AgAAAKBLcQQAAABAl0PVAAAWqOVrtw4dAQBY4hRHS5h1VgAAAIB74lA1AAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALqWDR0ApmHjmo1DRwAAAIBFT3EEALDErNqwfugIAMAioTgCAJKYrQkAwF0pju6BD9AAAADAUqY4AoAx+UIBAIClxlnVAAAAAOhSHAEAAADQpTgCAAAAoEtxBAAAAECX4ggAAACALmdVA2CinHkMAABmhxlHAAAAAHQpjgAAAADoUhwBAAAA0KU4AgAAAKBLcQQAAABA1yDFUVU9u6quqqrbq2rFEBkAAAAAuGdDzTi6MslvJtkw0P4BAAAAuBfLhthpa+3qJKmqIXYPAAAAwBiscQQAAABA19RmHFXV3yf5xc5Nf9Ja+8vdeJwXJXlRkixfvnxC6QAAAAC4N1Mrjlprj5/Q47wjyTuSZMWKFW0SjwkAAADAvXOoGgAAAABdgxRHVXVqVW1L8pgkf11VfztEDgAAAADu3lBnVbs4ycVD7BsAAACA8ThUDQAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACga9nQAYClYfnarUNHAAAAYDeZcQQAAABAl+IIAAAAgC6HqgEwczafvXroCAAAMBPMOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANClOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAANC1bOgAAADzYeOajUNHAABYdMw4AgAAAKBLcQQAAABAl+IIAAAAgC7FEQAAAABdiiMAAAAAuhRHAAAAAHQpjgAAAADoUhwBAAAA0KU4AgAAAKBLcQQAAABAl+IIAAAAgC7FEQAAAABdiiMAAAAAuhRHAAAAAHQpjgAAAADoUhwBAAAA0KU4AgAAAKBLcQQAAABAl+IIAAAAgC7FEQAAAABdiiMAAAAAuhRHAAAAAHQpjgAAAADoUhwBAAAA0FWttaEzjK2qtie5Zh53+eAk353H/c23WR7fLI8tMb7FzvgWr1keW2J8i53xLV6zPLbE+BY741u8ZnlsifFN2sNaawf3blhUxdF8q6pNrbUVQ+eYllke3yyPLTG+xc74Fq9ZHltifIud8S1eszy2xPgWO+NbvGZ5bInxzSeHqgEAAADQpTgCAAAAoEtxdM/eMXSAKZvl8c3y2BLjW+yMb/Ga5bElxrfYGd/iNctjS4xvsTO+xWuWx5YY37yxxhEAAAAAXWYcAQAAANClOBqpql+uqs9V1U+q6pW73PbkqvpyVX21ql4zVMZJqaoDquriqvpCVf1jVf2vQ2eapKp6UFX9VVV9vqquqqozhs40SVX1qqraMvpzZVXdVlUHDp1rkqrqlNH4rqqq9UPnmZTRuH6w0/O3duhM01BVJ47+Xj5r6CyTVFVPH71ubqmqTVX1a0NnmqSqet5ofF+oqs9W1bFDZ5qke3qfX+yq6l1V9Z2qunLoLJNWVQ+tqk9W1dWj94SXDZ1pkqpq79FnsTs+s7xu6EzTUFV7VNU/VdX/N3SWSauqr1fV1jveG4bOM0lV9XNVdVFVfWn0b/AxQ2ealKp65E6fx7ZU1Q+r6uVD55qkqvrD0evKlVV1QVXtPXSmSaqql43GdtUsPHe99/KqOrCqLq2qfx7994DB8jlUbU5V/XyShyV5RpLvt9beNLp+jyRfSfKEJNuSXJ7kua21Lw4U9X6rqrOT3Nhae11V/XKSt7XWHjd0rkmpqj9O8qDW2qur6uAkX07yi621WwaONnFV9RtJ/rC19tihs0xKVf1cks8meXJr7dqq+vnW2ncGjjURVXVKkle21n594ChTM3rNvDTJzUne1Vq7aOBIE1NV+yb5UWutVdUxST7QWvvloXNNSlX92yRXt9a+X1VPSbKutfbooXNNyt29z8+Cqjo5yY1JzmutzdqXQYckOaS1dkVV7Zdkc5JnLObPYTurqkrywNbajVW1Z5LPJHlZa+0fBo42UVX1vydZkWT/WXsPrKqvJ1nRWvvu0Fkmrarem+TTrbV3VtVeSR7QWvuXgWNN3Oizy/9M8ujW2jVD55mEqvqlzL2eHNla+3FVfSDJR1tr7xk22WSMJj5cmOSkJLck+Zskf9Ba++dBg90Pvffyqnpjku+11l5fcxNYDmitvXqIfGYcjbTWvtNauzzJrbvcdFKSr7bWvjYqHi5M8vR5DzhZRyb5eJK01r6U5LCq+oVhI01US7Lf6MPYvkm+l+Snw0aamucmuWDoEBP220k+3Fq7Npn7tzlwHnbPmiQfSjJzz1tr7cb2r9+2PDBzrzUzo7X22dba90cX/yHJoUPmmbR7eJ9f9FprGzL3XjdzWmvXtdauGP18Q5Krk/zSsKkmp825cXRxz9GfmXptqapDk/yHJO8cOgvjq6r9k5yc5Nwkaa3dMoul0cjjkvz3WSmNdrIsyT5VtSzJA5J8c+A8k/SoJP/QWruptfbTJOuTnDpwpvvlbt7Ln57kvaOf35u5L78GoTi6d7+U5Bs7Xd6Wxf+B5fNJfjNJquqkzH0DO0u/ILw1cy8m30yyNXPf3N0+bKTJq6oHJHly5n5JnyVHJDmgqj5VVZuravXQgSbsMaNDEj5WVUcNHWaSRt9unZrk7UNnmZaqOrWqvpTkr5P8ztB5puh3k3xs6BCws6o6LMmvJLls4CgTNTqMa0vmCvdLW2szNb4k/yXJHyWZuc9iIy3J340+s7xo6DAT9PAk25O8e3SY4Tur6oFDh5qS0zJjX8S21v5nkjcluTbJdUl+0Fr7u2FTTdSVSU6uqoNGvxM9NclDB840Db/QWrsumfsiJcnPDxVEcXTvqnPdYv8m6PWZ+8V8S+ZmB/xTZmtGzpOSbEnykCTHJXnr6FuTWfMbSTa21mbtW+ZlSU7I3LeTT0ryf1XVEcNGmpgrkjystXZsknOSXDJsnIn7L0le3Vq7begg09Jau3h0eNozkvyngeNMRVX9+8wVR4NMhYae0aGiH0ry8tbaD4fOM0mttdtaa8dl7ku8k2qG1p6sql9P8p3W2uahs0zRytba8UmekuTM0eEms2BZkuOT/Hlr7VeS/CjJol/rdVejQ/CeluSDQ2eZpNFaOE9Pcnjmfid6YFX9b8OmmpzW2tVJ3pC55RH+JnMTI2bp99kFZ0kXR1V15k4Loj3kbjbblju3l4dmEU7z23msSfZtrZ0x+pCyOsnBSf7HkPnur13Gd2bmDnVqrbWvZm5si3odkrv5uzoz347s8vx9M8nftNZ+NFovYEOSRbtIb+ff3o1J0lr7aJI9q+rBgwa8n3YZ34okF47We3hWkv9aVc8YMN79dnfvE6PpxI+Ypeevqh4yWrvpnUme3lq7fuh899eY7/MscKO1fz6U5PzW2oeHzjMto8OAPpW52cSzYmWSp43eFy5M8tiq+n+HjTRZrbVvjv77nSQXZ26Zi1mwLcm2nWbAXZS5ImnWPCXJFa21bw8dZMIen+R/tNa2t9ZuTfLhJP924EwT1Vo7t7V2fGvt5Mwd4rVo1ze6B98erfV3x5p/gy0FsaSLo9ba21prx43+3F0ZdHmSf1NVh48a6dOSfGT+Uk7GzmNNctNoLEnywiQbFvu3d7uM70uZO1Y5o7WbHpnkawPGu992/btaVQ9KsirJXw6dbRJ2ef4uTvLvqmrZaOrpozO3psWitMvYbh+tvXXHYaI/k2RR/3K+y9/Nw1trh7XWDsvcB8z/2Fq7ZNiE988uz98Ddnr+jk+yV2bo+cvct8sfTvL81tpXhk02GWO+z7OAjf7NnZu5hdv/dOg8k1ZVB9fcSSFSVftk7pe9Lw0aaoJaa/9Ha+3Q0fvCaUk+0VqbmVkPVfXA0aLtGR3G9cTMHUKz6LXWvpXkG1X1yNFVj0syE4vS72IW1wtN5g5R+9WquuOzy+OyiD9P99TcSS9SVcsztwzLLD6PH0ly+ujn0zPg737LhtrxQlNVv5hkU5L9M/fL3csztwr9D6vqJUn+NskemTtL0FXDJZ2IRyU5r6puy9wbwO8OnGfS/lOS91TV1swdavjqNntnujg1yd+11n40dJBJa61dXVV/k+QLmVsP4Z2ttZn4EJa5WTh/UFU/TfLjJKfttNgyC98zk6yuqlsz9/w9Z8aev7VJDsrcTLEk+WlrbcWwkSbnnt7nBw02AVV1QZJTkjy4qrYleW1r7dxhU03MyiTPT7J1NLMxSf54NGtzFhyS5L01d1ann8nc2Rpn7pT1M+wXklw8es1cluT9rbW/GTbSRK1Jcv7oC+evJTlj4DwTNfqC8glJfn/oLJPWWrusqi7K3DIJP83c0iTvGDbVxH2oqg7K3EkvztzpBB+LUu+9PHNLzHygqn43c2XgswfLN1ufeQEAAACYlCV9qBoAAAAAd09xBAAAAECX4ggAAACALsURAAAAAF2KIwAAAAC6FEcAADupqtuqaktVXVlVHxydsnl37v+Q0WmQU1XHVdVTd7rtaVX1mklnBgCYlmqtDZ0BAGDBqKobW2v7jn4+P8nm1tqf3sfHekGSFa21l0wwIgDAvDHjCADg7n06yf9SVQdW1SVV9YWq+oeqOiZJqmrVaHbSlqr6p6rar6oOG81W2ivJWUmeM7r9OVX1gqp66+i+D6uqj48e8+NVtXx0/Xuq6i1V9dmq+lpVPWuw0QMAS57iCACgo6qWJXlKkq1JXpfkn1prxyT54yTnjTZ7ZZIzW2vHJfl3SX58x/1ba7ckWZvkv7XWjmut/bdddvHWJOeNHvP8JG/Z6bZDkvxakl9P8voJDw0AYGyKIwCAO9unqrYk2ZTk2iTnZq7EeV+StNY+keSgqnpQko1J/rSqXprk51prP92N/TwmyftHP79vtI87XNJau7219sUkv3B/BgMAcH8sGzoAAMAC8+PRDKIdqqo627XW2uur6q+TPDXJP1TV45PcfB/3u/PCkz/Zeff38fEAAO43M44AAO7dhiTPS5KqOiXJd1trP6yqR7TWtrbW3pC5GUq/vMv9bkiy39085meTnDb6+XlJPjPp0AAA95fiCADg3q1LsqKqvpC5NYdOH13/8tFC2J/P3PpGH9vlfp9McuQdi2PvcttLk5wxesznJ3nZ1NIDANxH1Vq7960AAAAAWHLMOAIAAACgS3EEAAAAQJfiCAAAAIAuxREAAAAAXYojAAAAALoURwAAAAB0KY4AAAAA6FIcAQAAAND1/wPS6svp9dx7dgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_nuc(x):\n",
    "    return(x.str.split(\"_\")[1])\n",
    "\n",
    "def get_position(x):\n",
    "    if x.str.split(\"_\")[0] == \"A\": return 0\n",
    "    if x.str.split(\"_\")[0] == \"G\": return 0\n",
    "    return(int(x.str.split(\"_\")[0]))\n",
    "\n",
    "###Start code here\n",
    "\n",
    "data = pd.DataFrame({\"Position\" : F_importances[\"feature_name\"].str.split(\"_\", expand=True)[0],\n",
    "                    \"Nucleotide\" : F_importances[\"feature_name\"].str.split(\"_\", expand=True)[1],\n",
    "                    \"Importance\" : F_importances[\"importance\"]})\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = sns.barplot(data=data,\n",
    "    x=\"Position\", \n",
    "    y=\"Importance\", \n",
    "    hue=\"Nucleotide\"\n",
    "    )\n",
    "\n",
    "#End code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2.1._Classification_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
